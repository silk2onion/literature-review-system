 创建项目目录结构和初始化开发环境（backend 与 frontend 目录、基础配置文件）
2 搭建后端 FastAPI 服务与基础路由结构（健康检查、版本信息）
3 设计并创建 SQLite 数据库结构（Paper、Review、CrawlJob 等模型与迁移脚本）
4 实现基础文献爬虫模块（Arxiv 爬虫 + 请求与限流封装）
5 开发 OpenAI 兼容 LLM 接入模块（支持多种模型与 API Key 配置）
6 实现文献搜索与批量检索 API（按关键词、年份范围、数据源组合查询）
7 开发 LLM 综述生成功能（生成综述框架 + 详细内容，并将 summary_stats 写入 Review.analysis_json）
8 设计并实现长周期多轮抓取 + 去重入库 + 批量综述的整体方案和基础实现（CrawlJob 模型与 run_once 流程）
9 设计并实现本地文献库检索 API（基于领域、关键词、文献类型、是否同行评议等条件的组合查询）
10 实现前端“文献库”页面（基于本地库检索与筛选，列表展示，预留批量操作能力）
11 更新前端交互以支持长任务状态展示和管理（使用 /api/crawl/jobs/latest_status 进行轮询）
12 扩展多数据源爬虫 V2：设计 BaseCrawler 抽象与 SourcePaper 中间数据模型
13 扩展多数据源爬虫 V2：实现 ScholarSerpAPICrawler 与 ScopusCrawler 占位实现与配置项
14 扩展多数据源爬虫 V2：实现 MultiSourceOrchestrator 调度层（按源返回 SourcePaper 列表）
15 扩展多数据源爬虫 V2：实现 paper_ingest 模块，将 SourcePaper 去重后入库为 Paper
16 扩展多数据源爬虫 V2：将 MultiSourceOrchestrator 与 paper_ingest 接入 CrawlJob pipeline（改造 run_crawl_job_once）
17 扩展多数据源爬虫 V2：提供后端多源测试 API（/api/debug/external-sources/test）
18 前端增加“数据源设置与测试”弹窗（启用开关 + key 配置 + 调试结果展示，居中弹窗 + 遮罩样式）
19 设计与实现批量抓取任务系统的进一步监控与可视化（任务列表页、状态过滤、失败重试、暂停与恢复控制）
20 优化数据库结构以支撑上百篇甚至上千篇文献（关键字段索引、分页查询优化、必要时的分表或归档策略）
21 设计并实现 PhD 级多阶段综述管线（文献聚类 → 主题抽取 → 分章节大纲 → 章节级综述 → 总结）
22 综述导出与下载功能：后端支持导出为 Markdown/HTML/PDF，前端提供下载入口与格式选择）
23 文献 PDF 下载与本地缓存管理（从源站下载 PDF、存储 pdf_path、失败重试与异常日志）
24 明确当前爬虫与数据源对期刊分区和收录平台信息的支持边界（哪些源可提供影响因子、分区、收录情况）
25 为期刊分区与收录平台扩展设计后端方案（扩展 Paper 模型字段与相关 Pydantic Schema）
26 在后端服务层预留“期刊信息增强接口”占位函数与 API 路由（例如调用外部 Journal/Index 数据库）
27 在前端文献列表与详情视图中预留期刊分区与收录平台展示区域与交互文案）
28 将新增的期刊信息字段纳入多源去重与 LLM 提示词设计（让 LLM 在综述中合理利用分区/收录信息）
29 完整部署方案设计与实现（后端进程管理、环境变量配置、静态资源构建与反向代理配置）
30 编写系统文档（整体架构说明、主要模块说明、API 文档、前端使用说明、开发与贡献指南）
31 端到端集成测试（从城市设计主题关键词 → 多源抓取 → 去重入库 → LLM 综述 → 导出下载的全链路验证）
32 异常与鲁棒性测试（网络错误、第三方限流、LLM 接口超时、抓取失败重试策略验证）
33 新增支持文献分组的数据库结构（文献分组表 + 组与文献的关联表）
34 新增分组相关后端接口（创建/重命名/删除分组，批量将文献加入/移出分组，按分组查询文献列表）
35 前端文献库页面支持多选（每行选择框 + 全选），并提供“加入分组/从分组移除”等批量操作
36 前端分组管理界面（分组列表视图，可查看某个分组下的文献、重命名和删除分组）
37 基于分组的 LLM 综述入口（选择一个分组并调用现有综述生成逻辑，按分组文献生成综述）
38 分组与 LLM 上下文长度控制策略（限制单次综述使用的文献数量，必要时按优先级或年份裁剪分组内文献）
39 为 Paper 增加逻辑删除/归档字段（例如 is_archived、archived_reason、archived_at），并在检索 API 中默认过滤归档/删除文献）
40 新增后端批量删除/归档接口（接受 paper_ids 列表，支持软删除/归档为主，必要时提供“硬删除”管理端接口）
41 前端文献库多选批量操作扩展：在批量操作栏中增加“归档选中文献”“删除选中文献”，带二次确认与操作结果反馈）
42 实现后端语义组管理模块（SemanticGroupService，基于城市设计术语的语义组激活与关键词扩展）
43 将语义组网接入文献搜索与综述生成流程（搜索 API 使用语义组扩展关键词，LLM 提示词注入激活组信息，预留向量增强接口）
44 设计 RAG 可视化子系统整体架构（向量存储方案、检索流程、WebSocket 协议、前端面板布局）
45 实现 Paper 向量生成与批量回填服务（基于 LLM embedding，将标题与摘要编码写入 Paper.embedding 字段）
46 实现后端向量检索服务模块（支持语义组扩展查询，对 Paper.embedding 执行相似度检索并返回 top K）
47 实现语义检索 HTTP API（输入查询与筛选条件，返回向量检索结果及调试信息，如激活语义组与相似度）
48 设计并实现 RAG 语义检索 WebSocket 接口（例如 /ws/semantic-search，分批推送 partial_result、done、error 消息）
49 在前端新增“RAG 可视化调试”面板（接收 WebSocket 流式结果，显示文献列表、相似度、激活语义组标签和检索进度）
50 将 RAG 可视化面板集成到综述助手与文献库界面（搜索时可开启流式可视化，支持区分多个检索会话）
51 为 RAG 检索过程增加服务器端日志与基础指标（处理文献数量、耗时、错误记录），支持后续调试与优化）
52 更新系统文档，新增“可视化 RAG 系统”章节（架构说明、API 协议、前端使用方式与调参建议）
53 从上游 LLM 服务动态获取模型列表，并在前端设置弹窗中支持选择与刷新 LLM 与 Embedding 模型
54 修复前端文献库分页逻辑，解决“下一页”按钮不生效问题
55 将运行时模型选择接入 LLM 调用与 EmbeddingService（综述生成与向量编码统一使用所选模型）
56 设计并实现 StagingPaper 暂存文献模型（字段基本对齐 Paper，增加来源批次、抓取渠道、LLM 打标等元数据字段）
57 调整抓取与入库流程：爬虫输出 SourcePaper 时统一写入 StagingPaper 暂存库，不再直接写入 Paper 正式库
58 设计并实现暂存库查询 API（分页、按批次/关键词/状态过滤，预留按 LLM 打标标签与相关度排序能力）
59 实现暂存库到正式库的提升服务与 API（StagingPaper → Paper 去重合并，并在写入 Paper 时自动生成或更新 Paper.embedding）
60 为 Paper 正式库的新增/更新/删除操作挂钩 embedding 生成与清理逻辑（统一通过服务层封装，确保向量库与元数据同步）
61 在文档中补充“暂存库 + 正式库”二阶段抓取与审核流程及数据一致性策略说明（包括误操作保护与爬虫对比真实度的使用方式）
62 设计标签 / 标签组 / 文献的图结构与数据库表（Tag、TagGroup、PaperTag、TagGroupTag 等），与现有语义组体系协同工作
63 在检索与综述生成流程中记录召回相关的标签组与文献交互日志（查询、激活标签组、点击或被采纳的文献），作为自学习信号
64 基于标签共现与图传播机制设计召回增强算法（结合 embedding 检索，对候选文献进行扩展和重排）
65 评估“标签网 + 自学习召回增强”方案效果（与仅 embedding 基线对比召回率、精度和主观质量）
66 设计并实现文献引用关系数据模型（例如 Citation 或 PaperCitation，记录 citing_paper_id、cited_paper_id、来源与置信度），支持与标签图联动
67 设计获取与更新文献引用关系的管线（从 Scopus/Crossref 等外部源获取引用数据，或用 LLM 从参考文献列表中解析出引用关系）
68 基于引用图构建“引用衍生标签”（例如领域族群 cluster 标签、世代/代际标签、影响力分层标签），并写回 Tag / PaperTag 体系
69 在检索与综述生成流程中利用引用图（例如扩展候选文献、识别里程碑/综述论文、构建研究谱系或依赖关系视图）
70 评估“标签网 + 引用图”联合方案对综述实质内容与结构化程度的提升（包括引用覆盖度、关键论文识别率、用户主观评价）
71 后端：为综述助手页的抓取/搜索接口增加数据源筛选参数（例如 sources 数组，支持 arxiv、scholar_serpapi、scopus 等组合），并与 CrawlJob / MultiSourceOrchestrator 打通
72 前端：在综述助手页面为爬虫区域增加“数据源勾选”控件（复选框列表），默认开启常用源，支持关闭 arxiv 等，并将用户选择传入后端抓取/搜索请求