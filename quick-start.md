# å¿«é€Ÿå¯åŠ¨æŒ‡å— - åŸå¸‚è®¾è®¡æ–‡çŒ®ç»¼è¿°ç³»ç»Ÿ

## ç¯å¢ƒè¦æ±‚

- Python 3.9+
- Node.js 16+
- Git
- Redis (å¯é€‰ï¼Œç”¨äºç¼“å­˜)

## å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿæ­å»ºï¼‰

### æ­¥éª¤1ï¼šå…‹éš†é¡¹ç›®å¹¶åˆ›å»ºç›®å½•ç»“æ„

```bash
# åˆ›å»ºé¡¹ç›®æ ¹ç›®å½•
mkdir literature-review-system
cd literature-review-system

# åˆ›å»ºåŸºç¡€ç›®å½•ç»“æ„
mkdir -p backend/{app/{api,models,services/{crawler,llm,review},utils},tests}
mkdir -p frontend/{public,src/{components,pages,services,store}}
mkdir -p docker
mkdir -p docs
```

### æ­¥éª¤2ï¼šåç«¯å¿«é€Ÿè®¾ç½®

```bash
cd backend

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# åˆ›å»ºrequirements.txt
cat > requirements.txt << EOF
Flask==2.3.2
Flask-CORS==4.0.0
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
openai==1.3.0
scholarly==1.7.11
arxiv==1.4.8
beautifulsoup4==4.12.2
selenium==4.11.2
requests==2.31.0
python-dotenv==1.0.0
celery==5.3.1
redis==4.6.0
SQLAlchemy==2.0.19
pandas==2.0.3
numpy==1.24.3
EOF

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### æ­¥éª¤3ï¼šåˆ›å»ºæœ€å°å¯è¿è¡Œçš„åç«¯

```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶
cat > config.py << 'EOF'
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    SECRET_KEY = os.getenv('SECRET_KEY', 'dev-secret-key-change-in-production')
    SQLALCHEMY_DATABASE_URI = os.getenv('DATABASE_URL', 'sqlite:///literature.db')
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
EOF

# åˆ›å»º.envæ–‡ä»¶
cat > .env << EOF
SECRET_KEY=your-secret-key-here
OPENAI_API_KEY=your-openai-api-key-here
# å¦‚æœä½¿ç”¨å…¶ä»–å…¼å®¹APIï¼Œè®¾ç½®BASE_URL
# OPENAI_BASE_URL=https://your-api-endpoint.com/v1
EOF

# åˆ›å»ºä¸»åº”ç”¨æ–‡ä»¶
cat > run.py << 'EOF'
from flask import Flask, jsonify
from flask_cors import CORS
from flask_sqlalchemy import SQLAlchemy
from config import Config

app = Flask(__name__)
app.config.from_object(Config)
CORS(app)
db = SQLAlchemy(app)

@app.route('/api/health')
def health_check():
    return jsonify({'status': 'healthy', 'message': 'ç³»ç»Ÿè¿è¡Œæ­£å¸¸'})

@app.route('/api/papers/search', methods=['POST'])
def search_papers():
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    return jsonify({
        'success': True,
        'papers': [
            {
                'id': 1,
                'title': 'æ™ºæ…§åŸå¸‚è®¾è®¡çš„å¯æŒç»­å‘å±•ç­–ç•¥',
                'authors': ['å¼ ä¸‰', 'æå››'],
                'year': 2023,
                'source': 'google_scholar',
                'citations_count': 42
            }
        ]
    })

if __name__ == '__main__':
    with app.app_context():
        db.create_all()
    app.run(debug=True, port=5000)
EOF

# å¯åŠ¨åç«¯æœåŠ¡
python run.py
```

### æ­¥éª¤4ï¼šå‰ç«¯å¿«é€Ÿè®¾ç½®

æ‰“å¼€æ–°çš„ç»ˆç«¯çª—å£ï¼š

```bash
cd frontend

# åˆ›å»ºReactåº”ç”¨
npx create-react-app . --template typescript

# å®‰è£…é¢å¤–ä¾èµ–
npm install antd axios react-router-dom @ant-design/icons

# åˆ›å»ºç®€å•çš„ä¸»é¡µ
cat > src/App.tsx << 'EOF'
import React, { useState } from 'react';
import { Layout, Input, Button, Card, Table, message } from 'antd';
import { SearchOutlined } from '@ant-design/icons';
import axios from 'axios';
import 'antd/dist/reset.css';

const { Header, Content } = Layout;
const { Search } = Input;

const API_BASE_URL = 'http://localhost:5000/api';

function App() {
  const [loading, setLoading] = useState(false);
  const [papers, setPapers] = useState<any[]>([]);

  const handleSearch = async (value: string) => {
    if (!value.trim()) {
      message.warning('è¯·è¾“å…¥æœç´¢å…³é”®è¯');
      return;
    }

    setLoading(true);
    try {
      const response = await axios.post(`${API_BASE_URL}/papers/search`, {
        keywords: value.split(' '),
        sources: ['google_scholar', 'arxiv'],
        limit: 20
      });
      
      setPapers(response.data.papers);
      message.success(`æ‰¾åˆ° ${response.data.papers.length} ç¯‡æ–‡çŒ®`);
    } catch (error) {
      message.error('æœç´¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦è¿è¡Œ');
    } finally {
      setLoading(false);
    }
  };

  const columns = [
    {
      title: 'æ ‡é¢˜',
      dataIndex: 'title',
      key: 'title',
    },
    {
      title: 'ä½œè€…',
      dataIndex: 'authors',
      key: 'authors',
      render: (authors: string[]) => authors?.join(', '),
    },
    {
      title: 'å¹´ä»½',
      dataIndex: 'year',
      key: 'year',
    },
    {
      title: 'æ¥æº',
      dataIndex: 'source',
      key: 'source',
    },
    {
      title: 'å¼•ç”¨æ•°',
      dataIndex: 'citations_count',
      key: 'citations_count',
    },
  ];

  return (
    <Layout style={{ minHeight: '100vh' }}>
      <Header style={{ background: '#fff', padding: '0 24px' }}>
        <h1>åŸå¸‚è®¾è®¡æ–‡çŒ®ç»¼è¿°ç³»ç»Ÿ</h1>
      </Header>
      <Content style={{ padding: '24px' }}>
        <Card title="æ–‡çŒ®æœç´¢" style={{ marginBottom: 24 }}>
          <Search
            placeholder="è¾“å…¥å…³é”®è¯ï¼ˆå¦‚ï¼šåŸå¸‚è®¾è®¡ å¯æŒç»­å‘å±•ï¼‰"
            enterButton={<><SearchOutlined /> æœç´¢</>}
            size="large"
            onSearch={handleSearch}
            loading={loading}
          />
        </Card>
        
        <Card title="æœç´¢ç»“æœ">
          <Table
            columns={columns}
            dataSource={papers}
            rowKey="id"
            loading={loading}
          />
        </Card>
      </Content>
    </Layout>
  );
}

export default App;
EOF

# å¯åŠ¨å‰ç«¯æœåŠ¡
npm start
```

### æ­¥éª¤5ï¼šè®¿é—®åº”ç”¨

1. åç«¯è¿è¡Œåœ¨: http://localhost:5000
2. å‰ç«¯è¿è¡Œåœ¨: http://localhost:3000
3. å¥åº·æ£€æŸ¥: http://localhost:5000/api/health

## æ ¸å¿ƒåŠŸèƒ½å®ç°ç¤ºä¾‹

### 1. å®é™…çš„Google Scholarçˆ¬è™«

```python
# backend/app/services/crawler/scholar.py
from scholarly import scholarly
import time
import random

def search_google_scholar(keywords, limit=10):
    """æœç´¢Google Scholar"""
    results = []
    query = ' '.join(keywords)
    
    try:
        # é…ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # scholarly.use_proxy(http="http://your-proxy.com:8080")
        
        search_query = scholarly.search_pubs(query)
        
        for i, paper in enumerate(search_query):
            if i >= limit:
                break
                
            # æå–è®ºæ–‡ä¿¡æ¯
            info = paper['bib']
            paper_data = {
                'title': info.get('title', ''),
                'authors': info.get('author', '').split(' and '),
                'abstract': info.get('abstract', ''),
                'year': info.get('pub_year', ''),
                'venue': info.get('venue', ''),
                'url': paper.get('pub_url', ''),
                'citations': paper.get('num_citations', 0),
            }
            results.append(paper_data)
            
            # æ·»åŠ éšæœºå»¶è¿Ÿé¿å…è¢«å°
            time.sleep(random.uniform(1, 3))
            
    except Exception as e:
        print(f"æœç´¢é”™è¯¯: {e}")
        
    return results
```

### 2. OpenAIå…¼å®¹APIè°ƒç”¨

```python
# backend/app/services/llm/openai_service.py
from openai import OpenAI
import json

class LLMService:
    def __init__(self, api_key, base_url=None):
        """
        åˆå§‹åŒ–LLMæœåŠ¡
        æ”¯æŒOpenAIã€Azure OpenAIã€æœ¬åœ°éƒ¨ç½²æ¨¡å‹ç­‰
        """
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url  # è‡ªå®šä¹‰ç«¯ç‚¹
        )
    
    def generate_review(self, papers, prompt_template=None):
        """ç”Ÿæˆæ–‡çŒ®ç»¼è¿°"""
        # æ„å»ºæç¤ºè¯
        papers_text = self._format_papers(papers)
        
        prompt = prompt_template or f"""
        è¯·åŸºäºä»¥ä¸‹æ–‡çŒ®ç”Ÿæˆä¸€ç¯‡å…³äºåŸå¸‚è®¾è®¡çš„ç»¼è¿°ï¼š
        
        {papers_text}
        
        ç»¼è¿°è¦æ±‚ï¼š
        1. æ€»ç»“ä¸»è¦ç ”ç©¶è¶‹åŠ¿
        2. åˆ†æä¸åŒè§‚ç‚¹
        3. æŒ‡å‡ºç ”ç©¶ç©ºç™½
        4. æå‡ºæœªæ¥æ–¹å‘
        
        è¯·ç”¨ä¸­æ–‡æ’°å†™ï¼Œå­—æ•°2000å­—å·¦å³ã€‚
        """
        
        # è°ƒç”¨API
        response = self.client.chat.completions.create(
            model="gpt-4",  # æˆ–å…¶ä»–å…¼å®¹æ¨¡å‹
            messages=[
                {"role": "system", "content": "ä½ æ˜¯åŸå¸‚è®¾è®¡é¢†åŸŸçš„ä¸“å®¶"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=3000
        )
        
        return response.choices[0].message.content
    
    def _format_papers(self, papers):
        """æ ¼å¼åŒ–æ–‡çŒ®ä¿¡æ¯"""
        formatted = []
        for i, paper in enumerate(papers, 1):
            text = f"""
            æ–‡çŒ®{i}:
            æ ‡é¢˜: {paper.get('title')}
            ä½œè€…: {', '.join(paper.get('authors', []))}
            æ‘˜è¦: {paper.get('abstract', 'N/A')[:300]}...
            """
            formatted.append(text)
        return '\n'.join(formatted)
```

### 3. ç»¼è¿°ç”Ÿæˆå·¥ä½œæµ

```python
# backend/app/services/review/generator.py
class ReviewGenerator:
    def __init__(self, llm_service, db):
        self.llm = llm_service
        self.db = db
    
    def create_review(self, paper_ids, config):
        """åˆ›å»ºå®Œæ•´çš„æ–‡çŒ®ç»¼è¿°"""
        # 1. è·å–æ–‡çŒ®
        papers = self.db.get_papers_by_ids(paper_ids)
        
        # 2. ç”Ÿæˆå¤§çº²
        outline = self.llm.generate_outline(papers)
        
        # 3. ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå†…å®¹
        sections = []
        for section in outline['sections']:
            content = self.llm.generate_section(
                section, 
                papers,
                max_tokens=1000
            )
            sections.append(content)
        
        # 4. ç»„åˆæˆå®Œæ•´ç»¼è¿°
        review = self._combine_sections(outline, sections)
        
        # 5. ç”Ÿæˆå‚è€ƒæ–‡çŒ®
        references = self._format_references(papers)
        
        return {
            'title': outline['title'],
            'content': review,
            'references': references,
            'metadata': {
                'paper_count': len(papers),
                'word_count': len(review)
            }
        }
```

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### ä½¿ç”¨Dockeréƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t literature-review:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  -p 5000:5000 \
  -e OPENAI_API_KEY=your-key \
  -v $(pwd)/data:/app/data \
  literature-review:latest
```

### ä½¿ç”¨Nginxåå‘ä»£ç†

```nginx
server {
    listen 80;
    server_name your-domain.com;

    # å‰ç«¯é™æ€æ–‡ä»¶
    location / {
        root /var/www/frontend;
        try_files $uri /index.html;
    }

    # åç«¯API
    location /api {
        proxy_pass http://localhost:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## å¸¸è§é—®é¢˜è§£å†³

### 1. Google Scholarè¢«å°
- ä½¿ç”¨ä»£ç†æœåŠ¡å™¨
- é™ä½è¯·æ±‚é¢‘ç‡
- è€ƒè™‘ä½¿ç”¨SerpAPIç­‰ä»˜è´¹æœåŠ¡

### 2. OpenAI APIé…é¢é™åˆ¶
- å®ç°è¯·æ±‚ç¼“å­˜
- ä½¿ç”¨æµå¼è¾“å‡º
- è€ƒè™‘æœ¬åœ°éƒ¨ç½²å¼€æºæ¨¡å‹

### 3. å¤§é‡æ–‡çŒ®å¤„ç†
- ä½¿ç”¨Celeryå¼‚æ­¥ä»»åŠ¡
- å®ç°æ‰¹å¤„ç†
- æ·»åŠ è¿›åº¦æ¡æ˜¾ç¤º

## ä¸‹ä¸€æ­¥ä¼˜åŒ–

1. **æ·»åŠ æ›´å¤šæ•°æ®æº**
   - CNKIä¸­å›½çŸ¥ç½‘
   - Web of Science
   - Semantic Scholar

2. **å¢å¼ºLLMåŠŸèƒ½**
   - å¤šè¯­è¨€æ”¯æŒ
   - è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
   - ç»†ç²’åº¦å†…å®¹æ§åˆ¶

3. **æ”¹è¿›ç”¨æˆ·ä½“éªŒ**
   - å®æ—¶æœç´¢å»ºè®®
   - æ–‡çŒ®æ¨èç³»ç»Ÿ
   - åä½œåŠŸèƒ½

## è·å–å¸®åŠ©

- æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `docs/`
- æäº¤é—®é¢˜: GitHub Issues
- æŠ€æœ¯æ”¯æŒ: support@example.com

ç°åœ¨ä½ å¯ä»¥å¼€å§‹å¼€å‘äº†ï¼ğŸš€